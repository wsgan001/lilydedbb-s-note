# 字符串操作

### 消除标点符号

```python
import re
import string
from nltk.tokenize import word_tokenize

text = ["A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution.",
        "Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending."]
words = [word_tokenize(s) for s in text]
x = re.compile('[%s]' % re.escape(string.punctuation))
words_no_punts = []
for review in words:
    new_review = []
    for token in review:
        new_token = x.sub(u'', token)
        if not new_token == u'':
            new_review.append(new_token)
    words_no_punts.append(new_review)
print(words_no_punts)
# [['A', 'purely', u'peertopeer', 'version', 'of', 'electronic', 'cash', 'would', 'allow', 'online', 'payments', 'to', 'be', 'sent', 'directly', 'from', 'one', 'party', 'to', 'another', 'without', 'going', 'through', 'a', 'financial', 'institution'],
# ['Digital', 'signatures', 'provide', 'part', 'of', 'the', 'solution', 'but', 'the', 'main', 'benefits', 'are', 'lost', 'if', 'a', 'trusted', 'third', 'party', 'is', 'still', 'required', 'to', 'prevent', u'doublespending']]
```

### 大小写转换

```python
text = "Lily de DBB"
print(text.lower())  # lily de dbb
print(text.upper())  # LILY DE DBB
```

### 处理停止词

```python
# -*- coding: utf-8 -*-
import string
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords

text = "A purely peer-to-peer version of electronic cash would allow online payments to be sent directly from one party to another without going through a financial institution. Digital signatures provide part of the solution, but the main benefits are lost if a trusted third party is still required to prevent double-spending."
stops = set(stopwords.words('english'))
puncts = set([punct for punct in string.punctuation])
words = []
for s in list(sent_tokenize(text)):
    for w in word_tokenize(s):
        if w not in stops and w not in puncts:  # 去除停止词和标点
            words.append(w)
print (words)
# ['A', 'purely', 'peer-to-peer', 'version', 'electronic', 'cash', 'would', 'allow', 'online', 'payments', 'sent', 'directly', 'one', 'party', 'another', 'without', 'going', 'financial', 'institution', 'Digital', 'signatures', 'provide', 'part', 'solution', 'main', 'benefits', 'lost', 'trusted', 'third', 'party', 'still', 'required', 'prevent', 'double-spending']
```

### replacers (自定义)

```python
# replacers.py
# -*- coding: utf-8 -*-
import re
from nltk.corpus import wordnet

replacement_patterns = [
    (r'won\'t', 'will not'),
    (r'can\'t', 'cannot'),
    (r'i\'m', 'i am'),
    (r'ain\'t', 'is not'),
    (r'(\w+)\'ll', '\g<1> will'),
    (r'(\w+)n\'t', '\g<1> not'),
    (r'(\w+)\'ve', '\g<1> have'),
    (r'(\w+)\'s', '\g<1> is'),
    (r'(\w+)\'re', '\g<1> are'),
    (r'(\w+)\'d', '\g<1> would')
]


class RegexpReplacer(object):

    def __init__(self, patterns=replacement_patterns):
        self.patterns = [(re.compile(regexp), repl) for (regexp, repl) in patterns]

    def replace(self, text):
        s = text
        for (pattern, repl) in self.patterns:
            (s, count) = re.subn(pattern, repl, s)
        return s


# 去除重复字符
class RepeatReplacer(object):

    def __init__(self):
        self.repeat_regexp = re.compile(r'(\w*)(\w)\2(\w*)')
        self.repl = r'\1\2\3'

    def replace(self, word):
        if wordnet.synsets(word):  # 使用 wordnet 避免将本身就含有重复字符的单词误改，如 "happy"
            return word
        repl_word = self.repeat_regexp.sub(self.repl, word)
        if repl_word != word:
            return self.replace(repl_word)
        else:
            return repl_word


# 用单词的同义词替换
# 如果单词存在对应的同义词，则替换，否则返回原单词
class WordReplacer(object):

    def __init__(self, word_map):
        self.word_map = word_map

    def replace(self, word):
        return self.word_map.get(word, word)
```
