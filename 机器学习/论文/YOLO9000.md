# YOLO9000: Better, Faster, Stronger


- First we improve upon the base YOLO detection system to produce YOLOv2, a state-of-the-art, real-time detector.
- Then we use our dataset combination method and joint training algorithm to train a model on more than 9000 classes from ImageNet as well as detection data from COCO


### Batch Normalization

By **adding batch Normalization on all of the convolutional layers in YOLO**, we get more than 2% improvement in mAP.

### High Resolution Classifier

For YOLOv2 we first **fine tune the classification network at the full *448 x 448* resolution for *10* epochs on ImageNet**. This gives the network time to adjust its filter to work better on higher resolution input.

### Convolutional With Anchor Boxes

YOLO predicts the coordinates of bounding boxes directly using fully connected layers on top of the convolutional feature extractor. Faster RCNN uses only convolutional layers RPN to predict offsets and confidences for anchor boxes.

**Predicting offsets instead of coordinates simplifies the problem and make it easier for the network to learn.**

- First we eliminate one pooling layer to make the output of the network's convolutional layers higher resolution
- We also shrink the network to operate on ***416*** input images instead of ***448 x 448***.

    We do this because we want an odd number of locations in our feature map so there is a single center cell. Objects, especially large objects, tend to occupy the center of the image so it’s good to have a single location right at the center to predict these objects instead of four locations that are all nearby. YOLO’s convolutional layers downsam ple the image by a factor of ***32*** so by using an input image of ***416*** we get an output feature map of ***13 × 13***.
- Using anchor boxes we get a small decrease in accuracy. Even though the mAP decreases, the increase in recall means that our model has more room to improve.

### Dimension Cluster

Instead of choosing priors by hand, we run k-means clustering on the training set bounding boxes to automatically find good priors. If we use standard **k-means with Euclidean distance larger boxes generate more error than smaller boxes**. However, what we really want are priors that lead to good IOU scores, which is independent of the size of the box. Thus for our distance metric we use:

```math
d(box, centroid) = 1 - IOU(box, centroid)
```

We run k-means for various values of k and plot the average IOU with closest centroid. We choose ***k = 5*** as a good tradeoff between model complexity and high recall.
